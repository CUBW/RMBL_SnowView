{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import rasterio\n",
    "import time\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "from skimage import filters\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage.morphology import disk\n",
    "from skimage.segmentation import felzenszwalb, quickshift, slic, watershed\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from yellowbrick.classifier import ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_df(snow_path, mask_path, print_gabor=False, labeled=True):\n",
    "    #load in images\n",
    "    img = cv2.imread(snow_path)\n",
    "    if labeled:\n",
    "        mask = rasterio.open(mask_path)\n",
    "    \n",
    "    #generate grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #flatten image\n",
    "    img2 = img.reshape((-1,3))\n",
    "\n",
    "    #create dataframe\n",
    "    df = pd.DataFrame(img2, columns=['Blue', 'Green', 'Red'])\n",
    "    df['Gray'] = gray.reshape(-1)\n",
    "\n",
    "    #gabor filter\n",
    "    num = 1\n",
    "    gabors = [5, 11, 23, 8, 6, 4]\n",
    "    kernels = []\n",
    "    for theta in range(2):\n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1,3):\n",
    "            for lamda in np.arange(0, np.pi, np.pi/4):\n",
    "                for gamma in (.05, .5):\n",
    "                    if num in gabors:\n",
    "                        gabor_label = 'Gabor' + str(num)\n",
    "                        ksize = 9\n",
    "                        kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, 0, ktype=cv2.CV_32F)\n",
    "                        kernels.append(kernel)\n",
    "\n",
    "                        fimg = cv2.filter2D(gray, cv2.CV_8UC3, kernel)\n",
    "                        filtered_img = fimg.reshape(-1)\n",
    "                        df[gabor_label] = filtered_img\n",
    "                        if print_gabor:\n",
    "                            print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "                    num += 1\n",
    "\n",
    "    #Roberts Edge\n",
    "    roberts_edge = roberts(gray).reshape(-1)\n",
    "    df['Roberts'] = roberts_edge\n",
    "\n",
    "    #Sobel Edge\n",
    "    sobel_edge = sobel(gray).reshape(-1)\n",
    "    df['Sobel'] = sobel_edge\n",
    "\n",
    "    #Scharr Edge\n",
    "    scharr_edge = scharr(gray).reshape(-1)\n",
    "    df['Scharr'] = scharr_edge\n",
    "\n",
    "    #Prewitt Edge\n",
    "    prewitt_edge = prewitt(gray).reshape(-1)\n",
    "    df['Prewitt'] = prewitt_edge\n",
    "\n",
    "    gaussian_img = nd.gaussian_filter(gray, sigma=3).reshape(-1)\n",
    "    df['Gaussian s3'] = gaussian_img\n",
    "\n",
    "    gaussian_img2 = nd.gaussian_filter(gray, sigma=7).reshape(-1)\n",
    "    df['Gaussian s7'] = gaussian_img2\n",
    "\n",
    "    median_img =  nd.median_filter(gray, size=3).reshape(-1)\n",
    "    df['Median s3'] = median_img\n",
    "\n",
    "    #segmentation\n",
    "    #felzenszwalb\n",
    "    segments_fz = felzenszwalb(img, scale=100, sigma=0.5, min_size=50)\n",
    "    df['Felzenszwalb'] = segments_fz.reshape(-1)\n",
    "\n",
    "    #quickshift\n",
    "    segments_quick = quickshift(img, kernel_size=3, max_dist=6, ratio=0.5)\n",
    "    df['Quickshift'] = segments_quick.reshape(-1)\n",
    "\n",
    "    #slic\n",
    "    segments_slic = slic(img, n_segments=250, compactness=10, sigma=1)\n",
    "    df['SLIC'] = segments_slic.reshape(-1)\n",
    "\n",
    "    #watershed\n",
    "    gradient = filters.rank.gradient(gray, disk(2))\n",
    "    segments_ws = watershed(gradient, markers=250, compactness=0.001)\n",
    "    df['Watershed'] = segments_ws.reshape(-1)\n",
    "\n",
    "    #labels\n",
    "    if labeled:\n",
    "        df['labels'] = mask.read(1).reshape(-1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def data_prep():\n",
    "    csv_df = pd.read_csv('../data/640/640.csv')\n",
    "\n",
    "    #separate 10%(round up) of photos for testing\n",
    "    num_images = len(csv_df)\n",
    "    num_test_images = int(np.ceil(num_images * 0.1))\n",
    "    test_indices = np.random.choice(num_images, num_test_images, replace=False)\n",
    "\n",
    "    #write test indices to file\n",
    "    with open('test_indices.txt', 'w') as f:\n",
    "        for item in test_indices:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    #preprocessing of all training images\n",
    "    images_df = image_to_df(os.path.join(\"../\",csv_df['snow_path'][0]), os.path.join(\"../\",csv_df['snowbinary_path'][0]), print_gabor=True)\n",
    "\n",
    "    for i in tqdm(range(1, len(csv_df)), unit='image'):\n",
    "        if i in test_indices:\n",
    "            continue\n",
    "        images_df = pd.concat([images_df, image_to_df(os.path.join(\"../\",csv_df['snow_path'][i]), os.path.join(\"../\",csv_df['snowbinary_path'][i]))])\n",
    "\n",
    "    #remove all black pixels\n",
    "    trimmed_df = images_df[(images_df[['Blue', 'Green', 'Red']] != 0).all(axis=1)]\n",
    "\n",
    "    #train test split\n",
    "    X = trimmed_df.drop(columns=['labels'], axis=1)\n",
    "    y = trimmed_df['labels'].values\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2/.9, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gabor4 : theta= 0.0 : sigma= 1 : lamda= 0.7853981633974483 : gamma= 0.5\n",
      "Gabor5 : theta= 0.0 : sigma= 1 : lamda= 1.5707963267948966 : gamma= 0.05\n",
      "Gabor6 : theta= 0.0 : sigma= 1 : lamda= 1.5707963267948966 : gamma= 0.5\n",
      "Gabor8 : theta= 0.0 : sigma= 1 : lamda= 2.356194490192345 : gamma= 0.5\n",
      "Gabor11 : theta= 0.0 : sigma= 3 : lamda= 0.7853981633974483 : gamma= 0.05\n",
      "Gabor23 : theta= 0.7853981633974483 : sigma= 1 : lamda= 2.356194490192345 : gamma= 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [13:34<00:00,  6.26s/image]\n"
     ]
    }
   ],
   "source": [
    "data = data_prep()\n",
    "\n",
    "#store train test data with pickle\n",
    "with open('train_test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
